# --- ì‚¬ì´íŠ¸ ê´€ë¦¬ í•¨ìˆ˜ ---
def load_managed_sites():
    """ì €ì¥ëœ ì‚¬ì´íŠ¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not os.path.exists(SITES_FILE):
        return []
    
    try:
        with open(SITES_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        add_log(f"âŒ ì‚¬ì´íŠ¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return []

def save_managed_sites(sites):
    """ì‚¬ì´íŠ¸ ëª©ë¡ ì €ì¥í•˜ê¸°"""
    try:
        with open(SITES_FILE, 'w', encoding='utf-8') as f:
            json.dump(sites, f, indent=4, ensure_ascii=False)
        return True
    except Exception as e:
        add_log(f"âŒ ì‚¬ì´íŠ¸ ëª©ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False
        import tkinter as tk
from tkinter import messagebox, scrolledtext, filedialog, ttk
import threading
import time
import requests
import xml.etree.ElementTree as ET
import json
import os
import base64
import datetime
from cryptography.fernet import Fernet
from cryptography.hazmat.backends import default_backend
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC

# Google API ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# Selenium ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# Google API ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# Selenium ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# --- URL ë©”íƒ€ë°ì´í„° ê´€ë¦¬ íŒŒì¼ ---
URL_METADATA_FILE = 'url_metadata.json'  # URL ë©”íƒ€ë°ì´í„° (ìµœì´ˆ ë°œê²¬ ì‹œê°„, ìš°ì„ ìˆœìœ„ ë“±)

# --- ìƒ‰ì¸ ìš”ì²­ ê´€ë ¨ ìƒìˆ˜ ---
GOOGLE_BATCH_SIZE = 15  # êµ¬ê¸€ ìƒ‰ì¸ ìš”ì²­ ë°°ì¹˜ í¬ê¸°
BING_BATCH_SIZE = 15    # Bing ìƒ‰ì¸ ìš”ì²­ ë°°ì¹˜ í¬ê¸°
NAVER_BATCH_SIZE = 15   # ë„¤ì´ë²„ ìƒ‰ì¸ ìš”ì²­ ë°°ì¹˜ í¬ê¸°
RETRY_DELAY = 7200      # ì¬ì‹œë„ ì§€ì—° ì‹œê°„ (ì´ˆ) - 2ì‹œê°„

# --- ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ì„¤ì • ---
GOOGLE_TIMEOUT = 30     # êµ¬ê¸€ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
BING_TIMEOUT = 5        # Bing ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - ì‹¤ì œ ì‘ë‹µ ì‹œê°„ì— ë§ê²Œ ì¡°ì •
NAVER_TIMEOUT = 10      # ë„¤ì´ë²„ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - ë¡œë”© í‘œì‹œ ëŒ€ê¸°ìš©

# --- ì¼ì¼ í• ë‹¹ëŸ‰ ì„¤ì • ---
DAILY_QUOTA = {
    "Google": 15,  # êµ¬ê¸€ ì¼ì¼ í• ë‹¹ëŸ‰ (ê³µì‹ ì œí•œ)
    "Bing": 10,    # ë¹™ ì¼ì¼ í• ë‹¹ëŸ‰ (ì‹¤ì œ ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë°˜)
    "Naver": 20    # ë„¤ì´ë²„ ì¼ì¼ í• ë‹¹ëŸ‰ (ëª…ì‹œì  ì œí•œì€ ì—†ì§€ë§Œ ìì£¼ ìš”ì²­ ì‹œ ì œí•œ ê°€ëŠ¥ì„±)
}

# --- ìƒíƒœ ì½”ë“œ ---
STATUS_PENDING = "pending"    # ìš”ì²­ ì „ì†¡ ì „
STATUS_REQUESTED = "requested"  # ìš”ì²­ ì „ì†¡ë¨, ì‘ë‹µ ëŒ€ê¸° ì¤‘
STATUS_SUCCESS = "success"    # ìš”ì²­ ì„±ê³µ (ì‘ë‹µ ìˆ˜ì‹ )
STATUS_ERROR = "error"        # ìš”ì²­ ì‹¤íŒ¨
STATUS_TIMEOUT = "timeout"    # ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼
STATUS_UNKNOWN = "unknown"    # ìƒíƒœ ë¶ˆëª…í™•
STATUS_QUOTA_EXCEEDED = "quota_exceeded"  # í• ë‹¹ëŸ‰ ì´ˆê³¼

# --- ê¸°ë³¸ ì„¤ì •ê°’ ---
DEFAULT_CONFIG = {
    'google': {
        'service_account_file': '',
        'site_url': ''
    },
    'bing': {
        'api_key': ''
    },
    'naver': {
        'id': '',
        'password': '',
        'client_id': '',
        'client_secret': ''
    }
}

# --- ì „ì—­ ë³€ìˆ˜ (ì„¤ì •ê°’ ì €ì¥) ---
SERVICE_ACCOUNT_FILE = ''
SITE_URL = ''
SCOPES = ['https://www.googleapis.com/auth/indexing']
BING_API_KEY = ''
NAVER_ID = ''
NAVER_PASSWORD = ''
NAVER_CLIENT_ID = ''
NAVER_CLIENT_SECRET = ''

# --- ì¼ì¼ í• ë‹¹ëŸ‰ ê´€ë¦¬ í•¨ìˆ˜ ---
def load_daily_quota():
    """ì¼ì¼ í• ë‹¹ëŸ‰ ë° ì‚¬ìš©ëŸ‰ ë¡œë“œ"""
    if not os.path.exists(QUOTA_FILE):
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´ˆê¸° ì„¤ì •ìœ¼ë¡œ ìƒì„±
        quota_data = {
            "date": time.strftime("%Y-%m-%d"),
            "usage": {
                "Google": 0,
                "Bing": 0,
                "Naver": 0
            }
        }
        save_daily_quota(quota_data)
        return quota_data
    
    try:
        with open(QUOTA_FILE, 'r', encoding='utf-8') as f:
            quota_data = json.load(f)
            
        # ë‚ ì§œê°€ ì˜¤ëŠ˜ì´ ì•„ë‹ˆë©´ ì‚¬ìš©ëŸ‰ ì´ˆê¸°í™”
        today = time.strftime("%Y-%m-%d")
        if quota_data["date"] != today:
            quota_data["date"] = today
            quota_data["usage"] = {
                "Google": 0,
                "Bing": 0,
                "Naver": 0
            }
            save_daily_quota(quota_data)
            add_log(f"ğŸ“… ìƒˆë¡œìš´ ë‚ ì§œ ê°ì§€: ì¼ì¼ í• ë‹¹ëŸ‰ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return quota_data
    except Exception as e:
        add_log(f"âŒ ì¼ì¼ í• ë‹¹ëŸ‰ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "date": time.strftime("%Y-%m-%d"),
            "usage": {
                "Google": 0,
                "Bing": 0,
                "Naver": 0
            }
        }

def save_daily_quota(quota_data):
    """ì¼ì¼ í• ë‹¹ëŸ‰ ì •ë³´ ì €ì¥"""
    try:
        with open(QUOTA_FILE, 'w', encoding='utf-8') as f:
            json.dump(quota_data, f, indent=4, ensure_ascii=False)
        return True
    except Exception as e:
        add_log(f"âŒ ì¼ì¼ í• ë‹¹ëŸ‰ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def increment_usage_count(platform):
    """í”Œë«í¼ë³„ ì‚¬ìš©ëŸ‰ ì¦ê°€"""
    quota_data = load_daily_quota()
    if platform in quota_data["usage"]:
        quota_data["usage"][platform] += 1
        save_daily_quota(quota_data)
        return quota_data["usage"][platform]
    return 0

def get_remaining_quota(platform):
    """ë‚¨ì€ í• ë‹¹ëŸ‰ ë°˜í™˜"""
    quota_data = load_daily_quota()
    if platform in quota_data["usage"] and platform in DAILY_QUOTA:
        used = quota_data["usage"][platform]
        total = DAILY_QUOTA[platform]
        return max(0, total - used)
    return 0

def is_quota_exceeded(platform):
    """í• ë‹¹ëŸ‰ ì´ˆê³¼ ì—¬ë¶€ í™•ì¸"""
    return get_remaining_quota(platform) <= 0

def reset_daily_quota():
    """ì¼ì¼ í• ë‹¹ëŸ‰ ìˆ˜ë™ ì´ˆê¸°í™”"""
    quota_data = {
        "date": time.strftime("%Y-%m-%d"),
        "usage": {
            "Google": 0,
            "Bing": 0,
            "Naver": 0
        }
    }
    save_daily_quota(quota_data)
    add_log(f"ğŸ”„ ì¼ì¼ í• ë‹¹ëŸ‰ì´ ìˆ˜ë™ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True
def load_url_status():
    """ì €ì¥ëœ URL ìƒíƒœ ì •ë³´ ë¡œë“œ"""
    if not os.path.exists(URL_STATUS_FILE):
        return {}
    
    try:
        with open(URL_STATUS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        add_log(f"âŒ URL ìƒíƒœ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def save_url_status(status_data):
    """URL ìƒíƒœ ì •ë³´ ì €ì¥"""
    try:
        with open(URL_STATUS_FILE, 'w', encoding='utf-8') as f:
            json.dump(status_data, f, indent=4, ensure_ascii=False)
        return True
    except Exception as e:
        add_log(f"âŒ URL ìƒíƒœ ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def update_url_status(url, platform, status, last_attempt=None):
    """URL ìƒíƒœ ì •ë³´ ì—…ë°ì´íŠ¸"""
    if last_attempt is None:
        last_attempt = int(time.time())
    
    status_data = load_url_status()
    
    if url not in status_data:
        status_data[url] = {}
    
    status_data[url][platform] = {
        'status': status,
        'last_attempt': last_attempt
    }
    
    save_url_status(status_data)

def get_pending_urls(urls, platform, current_time=None):
    """ì²˜ë¦¬í•´ì•¼ í•  URL ëª©ë¡ ë°˜í™˜ (ì‹¤íŒ¨í•˜ê±°ë‚˜ ì•„ì§ ì‹œë„í•˜ì§€ ì•Šì€ URL)"""
    if current_time is None:
        current_time = int(time.time())
    
    status_data = load_url_status()
    pending_urls = []
    
    for url in urls:
        # URL ìƒíƒœê°€ ì—†ê±°ë‚˜ í•´ë‹¹ í”Œë«í¼ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
        if url not in status_data or platform not in status_data[url]:
            pending_urls.append(url)
            continue
        
        url_info = status_data[url][platform]
        status = url_info['status']
        
        # ì„±ê³µí•œ ê²½ìš° ì œì™¸
        if status == STATUS_SUCCESS:
            continue
        
        # ì‹¤íŒ¨, ì‹œê°„ ì´ˆê³¼, ë˜ëŠ” ë¶ˆëª…í™•í•œ ìƒíƒœì¸ ê²½ìš°
        if status in [STATUS_ERROR, STATUS_TIMEOUT, STATUS_UNKNOWN]:
            # ì¬ì‹œë„ ì‹œê°„ì´ ì§€ë‚¬ëŠ”ì§€ í™•ì¸
            if current_time - url_info['last_attempt'] >= RETRY_DELAY:
                pending_urls.append(url)
        else:
            # ìš”ì²­ ì¤‘ì´ê±°ë‚˜ ëŒ€ê¸° ì¤‘ì¸ ìƒíƒœëŠ” ë‹¤ì‹œ ìš”ì²­
            pending_urls.append(url)
    
    return pending_urls

def get_batch_urls(urls, platform, batch_size):
    """ë°°ì¹˜ ì²˜ë¦¬í•  URL ëª©ë¡ ë°˜í™˜"""
    pending_urls = get_pending_urls(urls, platform)
    return pending_urls[:batch_size]

def get_status_display(status):
    """ìƒíƒœ ì½”ë“œì— ëŒ€í•œ í‘œì‹œ í…ìŠ¤íŠ¸ ë°˜í™˜"""
    status_map = {
        STATUS_PENDING: "â³ ì¤€ë¹„ ì¤‘",
        STATUS_REQUESTED: "ğŸ”„ ìš”ì²­ ì¤‘",
        STATUS_SUCCESS: "âœ… ì„±ê³µ",
        STATUS_ERROR: "âŒ ì‹¤íŒ¨",
        STATUS_TIMEOUT: "â±ï¸ ì‹œê°„ ì´ˆê³¼",
        STATUS_UNKNOWN: "â“ ë¶ˆëª…í™•"
    }
    return status_map.get(status, status)

def open_site_manager():
    """ì‚¬ì´íŠ¸ ê´€ë¦¬ ì°½ ì—´ê¸°"""
    # ì´ë¯¸ ì—´ë ¤ìˆëŠ” ì°½ì´ ìˆìœ¼ë©´ í¬ì»¤ìŠ¤
    if hasattr(root, 'site_manager_window') and root.site_manager_window:
        root.site_manager_window.focus_force()
        return
    
    # ê´€ë¦¬ ì°½ ìƒì„±
    root.site_manager_window = tk.Toplevel(root)
    root.site_manager_window.title("ì‚¬ì´íŠ¸ ê´€ë¦¬")
    root.site_manager_window.geometry("700x500")
    root.site_manager_window.configure(bg="#2C3E50")
    root.site_manager_window.transient(root)
    root.site_manager_window.grab_set()
    
    # ì°½ ë‹«í ë•Œ ì²˜ë¦¬
    def on_manager_close():
        root.site_manager_window = None
        manager_window.destroy()
    
    root.site_manager_window.protocol("WM_DELETE_WINDOW", on_manager_close)
    
    manager_window = root.site_manager_window
    
    # í”„ë ˆì„ ìƒì„±
    sites_frame = tk.Frame(manager_window, bg="#34495E")
    sites_frame.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=10, pady=10)
    
    details_frame = tk.Frame(manager_window, bg="#34495E")
    details_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True, padx=10, pady=10)
    
    # ì‚¬ì´íŠ¸ ëª©ë¡ íƒ€ì´í‹€
    tk.Label(sites_frame, text="ë“±ë¡ëœ ì‚¬ì´íŠ¸", fg="white", bg="#34495E",
             font=("Segoe UI", 12, "bold")).pack(pady=10)
    
    # ì‚¬ì´íŠ¸ ëª©ë¡ í‘œì‹œ
    sites_listbox = tk.Listbox(sites_frame, width=30, height=15, 
                              font=("Segoe UI", 10), bg="#2D3748", fg="white",
                              selectbackground="#667eea")
    sites_listbox.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    # ìŠ¤í¬ë¡¤ë°” ì¶”ê°€
    scrollbar = tk.Scrollbar(sites_listbox)
    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
    sites_listbox.config(yscrollcommand=scrollbar.set)
    scrollbar.config(command=sites_listbox.yview)
    
    # ì‚¬ì´íŠ¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
    managed_sites = load_managed_sites()
    for site in managed_sites:
        sites_listbox.insert(tk.END, site['name'])
    
    # ìƒì„¸ ì •ë³´ í”„ë ˆì„
    tk.Label(details_frame, text="ì‚¬ì´íŠ¸ ì •ë³´", fg="white", bg="#34495E",
             font=("Segoe UI", 12, "bold")).pack(pady=10)
    
    details_inner_frame = tk.Frame(details_frame, bg="#34495E", padx=10, pady=10)
    details_inner_frame.pack(fill=tk.BOTH, expand=True)
    
    tk.Label(details_inner_frame, text="ì‚¬ì´íŠ¸ ì´ë¦„:", fg="white", bg="#34495E").grid(row=0, column=0, sticky=tk.W, pady=5)
    site_name_entry = tk.Entry(details_inner_frame, width=40)
    site_name_entry.grid(row=0, column=1, padx=5, pady=5, sticky=tk.W)
    
    tk.Label(details_inner_frame, text="ì‚¬ì´íŠ¸ URL:", fg="white", bg="#34495E").grid(row=1, column=0, sticky=tk.W, pady=5)
    site_url_entry = tk.Entry(details_inner_frame, width=40)
    site_url_entry.grid(row=1, column=1, padx=5, pady=5, sticky=tk.W)
    
    tk.Label(details_inner_frame, text="ì‚¬ì´íŠ¸ë§µ URL:", fg="white", bg="#34495E").grid(row=2, column=0, sticky=tk.W, pady=5)
    sitemap_url_entry = tk.Entry(details_inner_frame, width=40)
    sitemap_url_entry.grid(row=2, column=1, padx=5, pady=5, sticky=tk.W)
    
    # ë²„íŠ¼ í•¨ìˆ˜
    def clear_fields():
        """ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”"""
        site_name_entry.delete(0, tk.END)
        site_url_entry.delete(0, tk.END)
        sitemap_url_entry.delete(0, tk.END)
        sites_listbox.selection_clear(0, tk.END)
    
    def load_site_details(event=None):
        """ì„ íƒí•œ ì‚¬ì´íŠ¸ ì •ë³´ ë¡œë“œ"""
        selected_indices = sites_listbox.curselection()
        if not selected_indices:
            return
        
        index = selected_indices[0]
        if index < len(managed_sites):
            site = managed_sites[index]
            site_name_entry.delete(0, tk.END)
            site_url_entry.delete(0, tk.END)
            sitemap_url_entry.delete(0, tk.END)
            
            site_name_entry.insert(0, site['name'])
            site_url_entry.insert(0, site['url'])
            sitemap_url_entry.insert(0, site['sitemap'])
    
    def add_or_update_site():
        """ì‚¬ì´íŠ¸ ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸"""
        name = site_name_entry.get().strip()
        url = site_url_entry.get().strip()
        sitemap = sitemap_url_entry.get().strip()
        
        if not name or not url or not sitemap:
            messagebox.showwarning("ì…ë ¥ ì˜¤ë¥˜", "ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # URL í˜•ì‹ í™•ì¸
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        if not sitemap.startswith(('http://', 'https://')):
            sitemap = 'https://' + sitemap
        
        # ì„ íƒëœ í•­ëª©ì´ ìˆëŠ”ì§€ í™•ì¸
        selected_indices = sites_listbox.curselection()
        
        if selected_indices:  # ì—…ë°ì´íŠ¸
            index = selected_indices[0]
            managed_sites[index] = {
                'name': name,
                'url': url,
                'sitemap': sitemap
            }
            sites_listbox.delete(index)
            sites_listbox.insert(index, name)
            sites_listbox.selection_set(index)
            add_log(f"âœ… ì‚¬ì´íŠ¸ '{name}' ì •ë³´ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:  # ìƒˆë¡œ ì¶”ê°€
            # ë™ì¼í•œ ì´ë¦„ ì²´í¬
            for site in managed_sites:
                if site['name'] == name:
                    messagebox.showwarning("ì¤‘ë³µ ì˜¤ë¥˜", f"'{name}' ì´ë¦„ì˜ ì‚¬ì´íŠ¸ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                    return
            
            new_site = {
                'name': name,
                'url': url,
                'sitemap': sitemap
            }
            managed_sites.append(new_site)
            sites_listbox.insert(tk.END, name)
            add_log(f"âœ… ìƒˆ ì‚¬ì´íŠ¸ '{name}'ì´(ê°€) ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì €ì¥
        save_managed_sites(managed_sites)
        update_site_combobox()
        clear_fields()
    
    def delete_site():
        """ì„ íƒí•œ ì‚¬ì´íŠ¸ ì‚­ì œ"""
        selected_indices = sites_listbox.curselection()
        if not selected_indices:
            messagebox.showwarning("ì„ íƒ ì˜¤ë¥˜", "ì‚­ì œí•  ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        index = selected_indices[0]
        site_name = managed_sites[index]['name']
        
        confirm = messagebox.askyesno("ì‚­ì œ í™•ì¸", f"'{site_name}' ì‚¬ì´íŠ¸ë¥¼ ì •ë§ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        if not confirm:
            return
        
        del managed_sites[index]
        sites_listbox.delete(index)
        save_managed_sites(managed_sites)
        update_site_combobox()
        clear_fields()
        add_log(f"âœ… ì‚¬ì´íŠ¸ '{site_name}'ì´(ê°€) ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def use_selected_site():
        """ì„ íƒí•œ ì‚¬ì´íŠ¸ ì •ë³´ë¥¼ ë©”ì¸ ì°½ì— ì ìš©"""
        selected_indices = sites_listbox.curselection()
        if not selected_indices:
            messagebox.showwarning("ì„ íƒ ì˜¤ë¥˜", "ì‚¬ìš©í•  ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
        
        index = selected_indices[0]
        site = managed_sites[index]
        
        # ë©”ì¸ ì°½ ì½¤ë³´ë°•ìŠ¤ì— ì„ íƒ
        site_combobox.set(site['name'])
        sitemap_combobox.delete(0, tk.END)
        sitemap_combobox.insert(0, site['sitemap'])
        
        # ì‚¬ì´íŠ¸ URL ì„¤ì •ì— ë°˜ì˜
        global SITE_URL
        SITE_URL = site['url']
        save_config()
        
        on_manager_close()
        add_log(f"âœ… ì‚¬ì´íŠ¸ '{site['name']}'ì´(ê°€) ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì´ë²¤íŠ¸ ì—°ê²°
    sites_listbox.bind('<<ListboxSelect>>', load_site_details)
    
    # ë²„íŠ¼ í”„ë ˆì„
    button_frame = tk.Frame(details_frame, bg="#34495E")
    button_frame.pack(pady=10, fill=tk.X)
    
    add_button = tk.Button(button_frame, text="ì¶”ê°€/ì—…ë°ì´íŠ¸", command=add_or_update_site,
                         bg="#2ecc71", fg="white", width=12)
    add_button.pack(side=tk.LEFT, padx=5)
    
    clear_button = tk.Button(button_frame, text="ì…ë ¥ ì´ˆê¸°í™”", command=clear_fields,
                          bg="#3498db", fg="white", width=12)
    clear_button.pack(side=tk.LEFT, padx=5)
    
    delete_button = tk.Button(button_frame, text="ì‚­ì œ", command=delete_site,
                           bg="#e74c3c", fg="white", width=12)
    delete_button.pack(side=tk.LEFT, padx=5)
    
    # ì„ íƒ ë²„íŠ¼
    select_button = tk.Button(manager_window, text="ì„ íƒí•œ ì‚¬ì´íŠ¸ ì‚¬ìš©", command=use_selected_site,
                           bg="#667eea", fg="white", font=("Segoe UI", 10, "bold"),
                           height=2)
    select_button.pack(pady=10, fill=tk.X, padx=10)

def update_site_combobox():
    """ì‚¬ì´íŠ¸ ì½¤ë³´ë°•ìŠ¤ ì—…ë°ì´íŠ¸"""
    sites = load_managed_sites()
    site_names = [site['name'] for site in sites]
    site_combobox['values'] = site_names
    if sites:
        site_combobox.current(0)

def on_site_selected(event=None):
    """ì‚¬ì´íŠ¸ ì„ íƒ ì‹œ ì‚¬ì´íŠ¸ë§µ URL ì—…ë°ì´íŠ¸"""
    selected_site = site_combobox.get()
    sites = load_managed_sites()
    
    for site in sites:
        if site['name'] == selected_site:
            sitemap_combobox.delete(0, tk.END)
            sitemap_combobox.insert(0, site['sitemap'])
            
            # ì‚¬ì´íŠ¸ URL ì—…ë°ì´íŠ¸
            global SITE_URL
            SITE_URL = site['url']
            save_config()
            break

# --- Google API ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„± í•¨ìˆ˜ ---
def get_indexing_service():
    try:
        creds = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=SCOPES)
        service = build('indexing', 'v3', credentials=creds)
        return service
    except Exception as e:
        error_message = str(e)
        add_log(f"âŒ Google Indexing API ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„± ì‹¤íŒ¨: {error_message}")
        root.after(0, lambda msg=error_message: messagebox.showerror("API ì˜¤ë¥˜", f"Google Indexing API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. JSON í‚¤ íŒŒì¼ê³¼ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”:\n{msg}"))
        return None

# --- UI ìš”ì†Œ ìƒì„± ---
title_label = tk.Label(root, text="ğŸ” ê²€ìƒ‰ì—”ì§„ ìƒ‰ì¸ ìë™í™”",
                       font=("Segoe UI", 20, "bold"), fg="white", bg="#2C3E50")
title_label.pack(pady=15)

desc_label = tk.Label(root, text="ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•˜ê³  ìƒ‰ì¸ ìš”ì²­ì„ ë³´ë‚´ì„¸ìš”.",
                      font=("Segoe UI", 10), fg="white", bg="#2C3E50")
desc_label.pack(pady=5)

# ì‚¬ì´íŠ¸ ì„ íƒ í”„ë ˆì„
site_frame = tk.Frame(root, bg="#34495E", padx=10, pady=10)
site_frame.pack(pady=10, padx=20, fill=tk.X)

site_label = tk.Label(site_frame, text="ì‚¬ì´íŠ¸ ì„ íƒ",
                     font=("Segoe UI", 10, "bold"), fg="white", bg="#34495E")
site_label.pack(anchor=tk.W, pady=5)

# ì‚¬ì´íŠ¸ ì„ íƒ í”„ë ˆì„
site_selection_frame = tk.Frame(site_frame, bg="#34495E")
site_selection_frame.pack(fill=tk.X, pady=5)

# ì‚¬ì´íŠ¸ ì½¤ë³´ë°•ìŠ¤
site_combobox = ttk.Combobox(site_selection_frame, width=50, font=("Segoe UI", 10))
site_combobox.pack(side=tk.LEFT, padx=(0, 5))

# ì‚¬ì´íŠ¸ ê´€ë¦¬ ë²„íŠ¼
manage_sites_button = tk.Button(site_selection_frame, text="ì‚¬ì´íŠ¸ ê´€ë¦¬", 
                              command=open_site_manager, bg="#3498db", fg="white")
manage_sites_button.pack(side=tk.RIGHT)

# ì‚¬ì´íŠ¸ ì„ íƒ ì´ë²¤íŠ¸ ì—°ê²°
site_combobox.bind("<<ComboboxSelected>>", on_site_selected)

# ì‚¬ì´íŠ¸ë§µ í”„ë ˆì„
sitemap_frame = tk.Frame(root, bg="#34495E", padx=10, pady=10)
sitemap_frame.pack(pady=10, padx=20, fill=tk.X)

sitemap_label = tk.Label(sitemap_frame, text="ì‚¬ì´íŠ¸ë§µ URL",
                         font=("Segoe UI", 10, "bold"), fg="white", bg="#34495E")
sitemap_label.pack(anchor=tk.W, pady=5)

# ì½¤ë³´ë°•ìŠ¤ì™€ ì…ë ¥ í•„ë“œë¥¼ ë‹´ì„ í”„ë ˆì„
sitemap_input_frame = tk.Frame(sitemap_frame, bg="#34495E")
sitemap_input_frame.pack(fill=tk.X, pady=5)

# ì½¤ë³´ë°•ìŠ¤ë¡œ ë³€ê²½
sitemap_combobox = ttk.Combobox(sitemap_input_frame, width=70, font=("Courier New", 10))
sitemap_combobox.pack(side=tk.LEFT)
sitemap_combobox.insert(0, "https://www.sitemaps.org/sitemap.xml")  # ê¸°ë³¸ ì˜ˆì‹œ URL

platform_frame = tk.Frame(root, bg="#2C3E50")
platform_frame.pack(pady=10)

google_var = tk.BooleanVar()
bing_var = tk.BooleanVar()
naver_var = tk.BooleanVar()

google_check = tk.Checkbutton(platform_frame, text="Google Search Console", variable=google_var,
                              fg="white", bg="#2C3E50", selectcolor="#34495E")
bing_check = tk.Checkbutton(platform_frame, text="Bing Webmaster", variable=bing_var,
                            fg="white", bg="#2C3E50", selectcolor="#34495E")
naver_check = tk.Checkbutton(platform_frame, text="ë„¤ì´ë²„ ì„œì¹˜ì–´ë“œë°”ì´ì €", variable=naver_var,
                             fg="white", bg="#2C3E50", selectcolor="#34495E")

google_check.pack(side=tk.LEFT, padx=10)
bing_check.pack(side=tk.LEFT, padx=10)
naver_check.pack(side=tk.LEFT, padx=10)

# --- ê¸°ëŠ¥ í•¨ìˆ˜ ---
def add_log(message):
    timestamp = time.strftime("[%H:%M:%S]", time.localtime())
    log_area.insert(tk.END, f"{timestamp} {message}\n")
    log_area.see(tk.END)

def parse_sitemap(sitemap_url_str):
    urls = []
    try:
        add_log(f"ğŸ”— ì‚¬ì´íŠ¸ë§µ {sitemap_url_str} ë‹¤ìš´ë¡œë“œ ì¤‘...")
        response = requests.get(sitemap_url_str, timeout=10)
        response.raise_for_status()

        root_element = ET.fromstring(response.content)
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜, ì¼ë°˜ì ì¸ ê²½ìš°ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ê°œì„ 
        namespace = ''
        if '}' in root_element.tag:
            namespace = root_element.tag.split('}')[0] + '}' # {http://www.sitemaps.org/schemas/sitemap/0.9}

        # urlset / sitemap íƒœê·¸ ì°¾ê¸°
        if root_element.findall(f'{namespace}url'): # sitemapì¸ ê²½ìš°
            for url_element in root_element.findall(f'{namespace}url'):
                loc_element = url_element.find(f'{namespace}loc')
                if loc_element is not None:
                    url = loc_element.text
                    urls.append(url)
                    
                    # ìµœì¢… ìˆ˜ì • ì‹œê°„ í™•ì¸ (ìˆëŠ” ê²½ìš°)
                    lastmod_element = url_element.find(f'{namespace}lastmod')
                    if lastmod_element is not None and lastmod_element.text:
                        try:
                            # ISO 8601 í˜•ì‹ ë‚ ì§œë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜ (ì˜ˆ: 2023-01-01T12:00:00+00:00)
                            lastmod_str = lastmod_element.text
                            if 'T' in lastmod_str:  # ë‚ ì§œ+ì‹œê°„ í˜•ì‹
                                dt = datetime.datetime.fromisoformat(lastmod_str.replace('Z', '+00:00'))
                            else:  # ë‚ ì§œë§Œ ìˆëŠ” í˜•ì‹
                                dt = datetime.datetime.fromisoformat(f"{lastmod_str}T00:00:00+00:00")
                            
                            # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜
                            timestamp = int(dt.timestamp())
                            
                            # URL ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                            update_url_metadata(url, discovered_time=timestamp)
                        except Exception as e:
                            # ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨ ì‹œ í˜„ì¬ ì‹œê°„ ì‚¬ìš©
                            update_url_metadata(url)
                    else:
                        # lastmodê°€ ì—†ëŠ” ê²½ìš° ê·¸ëƒ¥ ë“±ë¡
                        update_url_metadata(url)
                    
        elif root_element.findall(f'{namespace}sitemap'): # sitemap indexì¸ ê²½ìš°
             add_log("ğŸ’¡ ì‚¬ì´íŠ¸ë§µ ì¸ë±ìŠ¤ íŒŒì¼ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤. í•˜ìœ„ ì‚¬ì´íŠ¸ë§µì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
             for sitemap_elem in root_element.findall(f'{namespace}sitemap'):
                loc_elem = sitemap_elem.find(f'{namespace}loc')
                if loc_elem is not None:
                    # ì¬ê·€ í˜¸ì¶œë¡œ í•˜ìœ„ ì‚¬ì´íŠ¸ë§µ íŒŒì‹± (ì¤‘ë³µ ì œê±° ìœ„í•´ set ì‚¬ìš© í›„ list ë³€í™˜)
                    urls.extend(list(set(parse_sitemap(loc_elem.text))))

        if not urls:
            add_log(f"â„¹ï¸ ì‚¬ì´íŠ¸ë§µì—ì„œ URLì„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜, ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ë£¨íŠ¸ íƒœê·¸: {root_element.tag})")
        else:
             add_log(f"âœ… ì‚¬ì´íŠ¸ë§µì—ì„œ ì´ {len(urls)}ê°œ URLì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")

    except requests.exceptions.RequestException as e:
        add_log(f"âŒ ì‚¬ì´íŠ¸ë§µ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        root.after(0, lambda err=e: messagebox.showerror("ì˜¤ë¥˜", f"ì‚¬ì´íŠ¸ë§µì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {err}"))
    except ET.ParseError as e:
        add_log(f"âŒ ì‚¬ì´íŠ¸ë§µ XML íŒŒì‹± ì˜¤ë¥˜: {e}")
        root.after(0, lambda err=e: messagebox.showerror("ì˜¤ë¥˜", f"ì‚¬ì´íŠ¸ë§µ XML í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {err}"))
    except Exception as e:
        add_log(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‚¬ì´íŠ¸ë§µ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        root.after(0, lambda err=e: messagebox.showerror("ì˜¤ë¥˜", f"ì‚¬ì´íŠ¸ë§µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {err}"))
    
    # URL ëª©ë¡ì„ ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬ (ë©”íƒ€ë°ì´í„° ê¸°ë°˜)
    urls = sorted(list(set(urls)), key=lambda url: -get_url_discovery_time(url))
    
    return urls

# --- ì‹¤ì œ Indexing API í˜¸ì¶œ í•¨ìˆ˜ë“¤ ---
def call_google_indexing_api(indexing_service, url):
    try:
        # í• ë‹¹ëŸ‰ í™•ì¸
        if is_quota_exceeded("Google"):
            add_log(f"âš ï¸ Google: ì¼ì¼ í• ë‹¹ëŸ‰({DAILY_QUOTA['Google']}ê°œ)ì„ ëª¨ë‘ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
            update_url_status(url, "Google", STATUS_QUOTA_EXCEEDED)
            return STATUS_QUOTA_EXCEEDED
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ìš”ì²­ ì „ì†¡ ì „
        add_log(f"ğŸ”„ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì¤€ë¹„ ì¤‘...")
        update_url_status(url, "Google", STATUS_PENDING)
        
        # ìš”ì²­ ë³¸ë¬¸ ì¤€ë¹„
        request_body = {
            "url": url,
            "type": "URL_UPDATED"
        }
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ìš”ì²­ ì „ì†¡ ì‹œì‘
        add_log(f"ğŸ“¤ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì „ì†¡ ì¤‘...")
        update_url_status(url, "Google", STATUS_REQUESTED)
        
        # ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°
        from concurrent.futures import ThreadPoolExecutor, TimeoutError
        
        def execute_request():
            return indexing_service.urlNotifications().publish(body=request_body).execute()
        
        with ThreadPoolExecutor() as executor:
            future = executor.submit(execute_request)
            try:
                response = future.result(timeout=GOOGLE_TIMEOUT)
                
                # ì‘ë‹µ ì²˜ë¦¬
                if response and response.get('urlNotificationMetadata'):
                    metadata = response.get('urlNotificationMetadata')
                    # ìš”ì²­ ë‚ ì§œ/ì‹œê°„ ì •ë³´ í™•ì¸
                    url_details = metadata.get('url', '')
                    latency = metadata.get('latencyMillis', '')
                    
                    # í• ë‹¹ëŸ‰ ì¦ê°€
                    usage_count = increment_usage_count("Google")
                    remaining = DAILY_QUOTA["Google"] - usage_count
                    
                    add_log(f"âœ… Google: {url} ìƒ‰ì¸ ìš”ì²­ ì„±ê³µ! (ì‘ë‹µ ì‹œê°„: {latency}ms, ì˜¤ëŠ˜ {usage_count}/{DAILY_QUOTA['Google']}ê°œ ì‚¬ìš©)")
                    update_url_status(url, "Google", STATUS_SUCCESS)
                    return STATUS_SUCCESS
                else:
                    add_log(f"âš ï¸ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì‘ë‹µ ë¶ˆë¶„ëª…. ì‘ë‹µ: {response}")
                    update_url_status(url, "Google", STATUS_UNKNOWN)
                    return STATUS_UNKNOWN
            
            except TimeoutError:
                add_log(f"â±ï¸ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({GOOGLE_TIMEOUT}ì´ˆ)")
                update_url_status(url, "Google", STATUS_TIMEOUT)
                return STATUS_TIMEOUT
    
    except HttpError as error:
        error_content = "ë‚´ìš© í™•ì¸ ë¶ˆê°€"
        try:
            error_content = error.content.decode('utf-8')
        except:
            pass # ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ì‚¬ìš©
        
        # í• ë‹¹ëŸ‰ ì´ˆê³¼ ë©”ì‹œì§€ í™•ì¸
        if "Quota exceeded" in error_content or "resource exhausted" in error_content:
            add_log(f"âŒ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì‹¤íŒ¨ - í• ë‹¹ëŸ‰ ì´ˆê³¼")
            update_url_status(url, "Google", STATUS_QUOTA_EXCEEDED)
            
            # í• ë‹¹ëŸ‰ ìƒíƒœ ì—…ë°ì´íŠ¸ (ëª¨ë‘ ì‚¬ìš©í•œ ê²ƒìœ¼ë¡œ í‘œì‹œ)
            quota_data = load_daily_quota()
            quota_data["usage"]["Google"] = DAILY_QUOTA["Google"]
            save_daily_quota(quota_data)
            
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ë©”ì‹œì§€ í‘œì‹œ ë° í”„ë¡œê·¸ë¨ ì¤‘ë‹¨ ìš”ì²­
            root.after(0, lambda: messagebox.showerror(
                "í• ë‹¹ëŸ‰ ì´ˆê³¼", 
                "Google Indexing API ì¼ì¼ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\n"
                "ë” ì´ìƒì˜ ìƒ‰ì¸ ìš”ì²­ì€ ë‚´ì¼ê¹Œì§€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n"
                "í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."
            ))
            return STATUS_QUOTA_EXCEEDED
        else:
            add_log(f"âŒ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì‹¤íŒ¨ (HTTP ì˜¤ë¥˜): {error_content}")
            update_url_status(url, "Google", STATUS_ERROR)
            return STATUS_ERROR
    
    except Exception as e:
        add_log(f"âŒ Google: {url} ìƒ‰ì¸ ìš”ì²­ ì‹¤íŒ¨ (ì¼ë°˜ ì˜¤ë¥˜): {e}")
        update_url_status(url, "Google", STATUS_ERROR)
        return STATUS_ERROR

def call_bing_indexing_api(url, bing_api_key):
    try:
        # í• ë‹¹ëŸ‰ í™•ì¸
        if is_quota_exceeded("Bing"):
            add_log(f"âš ï¸ Bing: ì¼ì¼ í• ë‹¹ëŸ‰({DAILY_QUOTA['Bing']}ê°œ)ì„ ëª¨ë‘ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
            update_url_status(url, "Bing", STATUS_QUOTA_EXCEEDED)
            return STATUS_QUOTA_EXCEEDED
        
        # ìœ íš¨ì„± ê²€ì‚¬
        if not bing_api_key or bing_api_key == 'YOUR_BING_API_KEY' or len(bing_api_key) < 10:
            add_log("âŒ Bing API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìš”ì²­ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            update_url_status(url, "Bing", STATUS_ERROR)
            return STATUS_ERROR
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ìš”ì²­ ì „ì†¡ ì „
        add_log(f"ğŸ”„ Bing: {url} ìƒ‰ì¸ ìš”ì²­ ì¤€ë¹„ ì¤‘...")
        update_url_status(url, "Bing", STATUS_PENDING)
        
        # ìš”ì²­ ì¤€ë¹„
        headers = {'Content-Type': 'application/json; charset=utf-8'}
        payload = {
            "siteUrl": SITE_URL,
            "urlList": [url]
        }
        
        api_url = f"https://ssl.bing.com/webmaster/api.svc/json/SubmitUrl?apikey={bing_api_key}"
        if "SubmitUrlBatch" not in api_url:
            payload = {'siteUrl': SITE_URL, 'url': url}
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ìš”ì²­ ì „ì†¡ ì‹œì‘
        add_log(f"ğŸ“¤ Bing: {url} ìƒ‰ì¸ ìš”ì²­ ì „ì†¡ ì¤‘...")
        update_url_status(url, "Bing", STATUS_REQUESTED)
        
        # ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ìš”ì²­ ì „ì†¡ ë° ì‘ë‹µ ëŒ€ê¸°
        from concurrent.futures import ThreadPoolExecutor, TimeoutError
        
        def execute_request():
            return requests.post(api_url, headers=headers, data=json.dumps(payload))
        
        with ThreadPoolExecutor() as executor:
            future = executor.submit(execute_request)
            try:
                response = future.result(timeout=BING_TIMEOUT)
                response.raise_for_status()
                
                # ì‘ë‹µ ì²˜ë¦¬
                try:
                    response_json = response.json()
                    response_details = str(response_json)
                except:
                    response_details = f"HTTP {response.status_code}"
                
                # í• ë‹¹ëŸ‰ ì¦ê°€
                usage_count = increment_usage_count("Bing")
                remaining = DAILY_QUOTA["Bing"] - usage_count
                
                add_log(f"âœ… Bing: {url} ìƒ‰ì¸ ìš”ì²­ ì„±ê³µ! (ì‘ë‹µ: {response_details}, ì˜¤ëŠ˜ {usage_count}/{DAILY_QUOTA['Bing']}ê°œ ì‚¬ìš©)")
                update_url_status(url, "Bing", STATUS_SUCCESS)
                return STATUS_SUCCESS
            
            except TimeoutError:
                add_log(f"â±ï¸ Bing: {url} ìƒ‰ì¸ ìš”ì²­ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ ({BING_TIMEOUT}ì´ˆ)")
                update_url_status(url, "Bing", STATUS_TIMEOUT)
                return STATUS_TIMEOUT

    except requests.exceptions.HTTPError as e:
        error_content = e.response.text
        
        # í• ë‹¹ëŸ‰ ì´ˆê³¼ í™•ì¸ (Bingì€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œì‹œí•  ìˆ˜ ìˆìŒ)
        if e.response.status_code == 429 or "quota" in error_content.lower() or "limit" in error_content.lower():
            add_log(f"âŒ Bing: {url} ìƒ‰ì¸ ìš”ì²­ ì‹¤íŒ¨ - í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°€ëŠ¥ì„±")
            update_url_status(url, "Bing", STATUS_QUOTA_EXCEEDED)
            
            # í• ë‹¹ëŸ‰ ìƒíƒœ ì—…ë°ì´íŠ¸
            quota_data = load_daily_quota()
            quota_data["usage"]["Bing"] = DAILY_QUOTA["Bing"]
            save_daily_quota(quota_data)
            
            # ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
            root.after(0, lambda: messagebox.showwarning(
                "Bing í• ë‹¹ëŸ‰ ì´ˆê³¼", 
                "Bing API ì¼ì¼ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
                "ë” ì´ìƒì˜ Bing ìƒ‰ì¸ ìš”ì²­ì€ ë‚´ì¼ê¹Œì§€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
            ))
            return STATUS_QUOTA_EXCEEDED
        else:
            add_log(f"âŒ Bing: {url} ìƒ‰ì¸ ìš”ì²­ HTTP ì˜¤ë¥˜ ({e.response.status_code}): {error_content}")
            update_url_status(url, "Bing", STATUS_ERROR)
            return STATUS_ERROR
    
    except requests.exceptions.RequestException as e:
        add_log(f"âŒ Bing: {url} ìƒ‰ì¸ ìš”ì²­ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        update_url_status(url, "Bing", STATUS_ERROR)
        return STATUS_ERROR
    
    except Exception as e:
        add_log(f"âŒ Bing: {url} ìƒ‰ì¸ ìš”ì²­ ì¼ë°˜ ì˜¤ë¥˜: {e}")
        update_url_status(url, "Bing", STATUS_ERROR)
        return STATUS_ERROR

# ë„¤ì´ë²„ ì„œì¹˜ì–´ë“œë°”ì´ì € ìë™í™” í•¨ìˆ˜ (Selenium ì‚¬ìš©)
def call_naver_search_advisor(url):
    try:
        # í• ë‹¹ëŸ‰ í™•ì¸
        if is_quota_exceeded("Naver"):
            add_log(f"âš ï¸ Naver: ì¼ì¼ í• ë‹¹ëŸ‰({DAILY_QUOTA['Naver']}ê°œ)ì„ ëª¨ë‘ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.")
            update_url_status(url, "Naver", STATUS_QUOTA_EXCEEDED)
            return STATUS_QUOTA_EXCEEDED
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸: ìš”ì²­ ì „ì†¡ ì „
        add_log(f"ğŸ”„ Naver: {url} ì„œì¹˜ì–´ë“œë°”ì´ì € ìë™í™” ì¤€ë¹„ ì¤‘...")
        update_url_status(url, "Naver", STATUS_PENDING)
        
        # ë¸Œë¼ìš°ì € ì„¤ì •
        chrome_options = Options()
        # chrome_options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ ì‹œ í™œì„±í™”
        chrome_options.add_argument("--window-size=1920,1080")
        
        # ì›¹ë“œë¼ì´ë²„ ì„¤ì •
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
        
        try:
            # ìƒíƒœ ì—…ë°ì´íŠ¸: ë¸Œë¼ìš°ì € ì‹¤í–‰ ë° ìë™í™” ì‹œì‘
            add_log(f"ğŸŒ Naver: {url} ë¸Œë¼ìš°ì € ìë™í™” ì‹œì‘...")
            update_url_status(url, "Naver", STATUS_REQUESTED)
            
            # ë„¤ì´ë²„ ë¡œê·¸ì¸ í˜ì´ì§€ ì ‘ì†
            driver.get("https://nid.naver.com/nidlogin.login")
            time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            add_log(f"ğŸ”‘ Naver: ë¡œê·¸ì¸ ì¤‘...")
            
            # ì•„ì´ë”” ì…ë ¥
            id_field = driver.find_element(By.ID, "id")
            id_field.send_keys(NAVER_ID)
            
            # ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
            pw_field = driver.find_element(By.ID, "pw")
            pw_field.send_keys(NAVER_PASSWORD)
            
            # ë¡œê·¸ì¸ ë²„íŠ¼ í´ë¦­
            login_button = driver.find_element(By.ID, "log.login")
            login_button.click()
            
            # ë¡œê·¸ì¸ ì™„ë£Œ ëŒ€ê¸°
            try:
                WebDriverWait(driver, 10).until(
                    EC.url_changes("https://nid.naver.com/nidlogin.login")
                )
                add_log(f"âœ… Naver: ë¡œê·¸ì¸ ì„±ê³µ!")
            except:
                add_log(f"âš ï¸ Naver: ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ë¶ˆê°€, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
            
            # ì„œì¹˜ì–´ë“œë°”ì´ì € í˜ì´ì§€ë¡œ ì´ë™
            add_log(f"ğŸ”„ Naver: ì„œì¹˜ì–´ë“œë°”ì´ì € í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
            driver.get("https://searchadvisor.naver.com/console/board")
            time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            
            # ì›¹ í˜ì´ì§€ ìˆ˜ì§‘ ìš”ì²­ í˜ì´ì§€ë¡œ ì´ë™
            add_log(f"ğŸ”„ Naver: ì›¹ í˜ì´ì§€ ìˆ˜ì§‘ ìš”ì²­ í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...")
            driver.get("https://searchadvisor.naver.com/console/request")
            time.sleep(2)
            
            # URL ì…ë ¥ í•„ë“œ ì°¾ê¸° ë° ì…ë ¥
            add_log(f"ğŸ“ Naver: URL ì…ë ¥ ì¤‘...")
            
            try:
                url_field = driver.find_element(By.CSS_SELECTOR, "input[placeholder='URLì„ ì…ë ¥í•˜ì„¸ìš”']")
                url_field.clear()
                url_field.send_keys(url)
                
                # ìˆ˜ì§‘ ìš”ì²­ ë²„íŠ¼ í´ë¦­
                add_log(f"ğŸ“¤ Naver: ìˆ˜ì§‘ ìš”ì²­ ì œì¶œ ì¤‘...")
                submit_button = driver.find_element(By.XPATH, "//button[contains(text(), 'ìˆ˜ì§‘ ìš”ì²­')]")
                submit_button.click()
                
                # ë¡œë”© í‘œì‹œ ê°ì§€ ë° ëŒ€ê¸°
                add_log(f"â³ Naver: ë¡œë”© ì¤‘... (ì•½ 5ì´ˆ ì†Œìš”)")
                
                # ë¡œë”© ì¸ë””ì¼€ì´í„° ê°ì§€ ì‹œë„
                loading_detected = False
                try:
                    # ë¡œë”© ì¸ë””ì¼€ì´í„° ì°¾ê¸° (CSS ì„ íƒìëŠ” ì‹¤ì œ ë„¤ì´ë²„ í˜ì´ì§€ì— ë§ê²Œ ì¡°ì • í•„ìš”)
                    loading_element = WebDriverWait(driver, 3).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "div.loading, span.loading, .spinner, .loader"))
                    )
                    loading_detected = True
                    add_log(f"â³ Naver: ë¡œë”© í‘œì‹œ ê°ì§€ë¨, ì™„ë£Œ ëŒ€ê¸° ì¤‘...")
                except:
                    add_log(f"â„¹ï¸ Naver: ë¡œë”© í‘œì‹œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì™„ë£Œ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤...")
                
                # ë¡œë”©ì´ ê°ì§€ë˜ì—ˆë‹¤ë©´, ë¡œë”© í‘œì‹œê°€ ì‚¬ë¼ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°
                if loading_detected:
                    try:
                        WebDriverWait(driver, NAVER_TIMEOUT).until(
                            EC.invisibility_of_element_located((By.CSS_SELECTOR, "div.loading, span.loading, .spinner, .loader"))
                        )
                        
                        # í• ë‹¹ëŸ‰ ì¦ê°€
                        usage_count = increment_usage_count("Naver")
                        remaining = DAILY_QUOTA["Naver"] - usage_count
                        
                        add_log(f"âœ… Naver: ë¡œë”© ì™„ë£Œ, ìš”ì²­ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤! (ì˜¤ëŠ˜ {usage_count}/{DAILY_QUOTA['Naver']}ê°œ ì‚¬ìš©)")
                        update_url_status(url, "Naver", STATUS_SUCCESS)
                        
                        # ë„¤ì´ë²„ ìš”ì²­ ê°„ ì¶”ê°€ ì§€ì—° (ì œí•œ ë°©ì§€)
                        add_log(f"â±ï¸ Naver: ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´ ì¶”ê°€ ëŒ€ê¸° ì¤‘... (ë„¤ì´ë²„ ì œí•œ ë°©ì§€)")
                        time.sleep(5)  # ë„¤ì´ë²„ ìš”ì²­ ê°„ ì¶”ê°€ 5ì´ˆ ëŒ€ê¸°
                        
                        return STATUS_SUCCESS
                    except:
                        add_log(f"âš ï¸ Naver: ë¡œë”© ì™„ë£Œ ê°ì§€ ì‹¤íŒ¨, í•˜ì§€ë§Œ ìš”ì²­ì€ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        update_url_status(url, "Naver", STATUS_UNKNOWN)
                        return STATUS_UNKNOWN
                else:
                    # ë¡œë”©ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ë‹¤ë©´ 5ì´ˆ ëŒ€ê¸° í›„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                    time.sleep(5)
                    
                    # í• ë‹¹ëŸ‰ ì¦ê°€
                    usage_count = increment_usage_count("Naver")
                    remaining = DAILY_QUOTA["Naver"] - usage_count
                    
                    add_log(f"âœ… Naver: {url} ìˆ˜ì§‘ ìš”ì²­ ì „ì†¡ ì™„ë£Œ (ì˜¤ëŠ˜ {usage_count}/{DAILY_QUOTA['Naver']}ê°œ ì‚¬ìš©)")
                    update_url_status(url, "Naver", STATUS_SUCCESS)
                    
                    # ë„¤ì´ë²„ ìš”ì²­ ê°„ ì¶”ê°€ ì§€ì—° (ì œí•œ ë°©ì§€)
                    add_log(f"â±ï¸ Naver: ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´ ì¶”ê°€ ëŒ€ê¸° ì¤‘... (ë„¤ì´ë²„ ì œí•œ ë°©ì§€)")
                    time.sleep(5)  # ë„¤ì´ë²„ ìš”ì²­ ê°„ ì¶”ê°€ 5ì´ˆ ëŒ€ê¸°
                    
                    return STATUS_SUCCESS
                
            except Exception as e:
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€ ì‹œë„ (ë©”ì‹œì§€ ë˜ëŠ” ìš”ì†Œ ê¸°ë°˜)
                try:
                    quota_exceeded_element = driver.find_element(By.XPATH, "//div[contains(text(), 'í• ë‹¹ëŸ‰') or contains(text(), 'ì œí•œ') or contains(text(), 'ì´ˆê³¼')]")
                    if quota_exceeded_element:
                        add_log(f"âŒ Naver: {url} ìƒ‰ì¸ ìš”ì²­ ì‹¤íŒ¨ - í• ë‹¹ëŸ‰ ì´ˆê³¼")
                        update_url_status(url, "Naver", STATUS_QUOTA_EXCEEDED)
                        
                        # í• ë‹¹ëŸ‰ ìƒíƒœ ì—…ë°ì´íŠ¸
                        quota_data = load_daily_quota()
                        quota_data["usage"]["Naver"] = DAILY_QUOTA["Naver"]
                        save_daily_quota(quota_data)
                        
                        # ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼
                        root.after(0, lambda: messagebox.showwarning(
                            "ë„¤ì´ë²„ í• ë‹¹ëŸ‰ ì´ˆê³¼", 
                            "ë„¤ì´ë²„ ì„œì¹˜ì–´ë“œë°”ì´ì € ì¼ì¼ í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.\n"
                            "ë” ì´ìƒì˜ ë„¤ì´ë²„ ìƒ‰ì¸ ìš”ì²­ì€ ë‚´ì¼ê¹Œì§€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
                        ))
                        return STATUS_QUOTA_EXCEEDED
                except:
                    pass
                
                add_log(f"âŒ Naver: {url} ìš”ì†Œ ì°¾ê¸° ë˜ëŠ” ì…ë ¥ ì‹¤íŒ¨: {e}")
                update_url_status(url, "Naver", STATUS_ERROR)
                return STATUS_ERROR
            
        finally:
            # ë¸Œë¼ìš°ì € ì¢…ë£Œ
            driver.quit()
            
    except Exception as e:
        add_log(f"âŒ Naver: {url} ì„œì¹˜ì–´ë“œë°”ì´ì € ìë™í™” ì‹¤íŒ¨: {e}")
        update_url_status(url, "Naver", STATUS_ERROR)
        return STATUS_ERROR

# ê¸°ì¡´ ë„¤ì´ë²„ API í•¨ìˆ˜ëŠ” ì£¼ì„ ì²˜ë¦¬í•˜ê³  ì›¹ ìë™í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©
def call_naver_indexing_api(url, client_id, client_secret):
    # ì›¹ ìë™í™” í•¨ìˆ˜ í˜¸ì¶œ
    return call_naver_search_advisor(url)

# --- ë©”ì¸ ìƒ‰ì¸ í”„ë¡œì„¸ìŠ¤ í•¨ìˆ˜ ---
def start_indexing_process():
    sitemap_url_str = sitemap_combobox.get().strip()

    google_enabled = google_var.get()
    bing_enabled = bing_var.get()
    naver_enabled = naver_var.get()

    if not sitemap_url_str:
        messagebox.showwarning("ê²½ê³ ", "ì‚¬ì´íŠ¸ë§µ URLì„ ì…ë ¥í•˜ì„¸ìš”.")
        return
    
    if not (google_enabled or bing_enabled or naver_enabled):
        messagebox.showwarning("ê²½ê³ ", "ìµœì†Œ í•˜ë‚˜ì˜ í”Œë«í¼ì„ ì„ íƒí•˜ì„¸ìš”.")
        return

    # ì‚¬ì´íŠ¸ë§µ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
    save_sitemap_history(sitemap_url_str)
    update_sitemap_combobox()

    add_log("ğŸš€ ìƒ‰ì¸ ìš”ì²­ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ë²„íŠ¼ ë¹„í™œì„±í™” (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
    request_button.config(state=tk.DISABLED)
    
    threading.Thread(target=indexing_task_thread, 
                     args=(sitemap_url_str, google_enabled, bing_enabled, naver_enabled),
                     daemon=True).start() # daemon=True ì¶”ê°€ (ë©”ì¸ ì°½ ì¢…ë£Œ ì‹œ ìŠ¤ë ˆë“œë„ ì¢…ë£Œ)

def indexing_task_thread(sitemap_url_str, google_enabled, bing_enabled, naver_enabled):
    urls = parse_sitemap(sitemap_url_str)
    if not urls:
        root.after(0, add_log, "âŒ ì‚¬ì´íŠ¸ë§µì—ì„œ ìœ íš¨í•œ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        root.after(0, lambda: request_button.config(state=tk.NORMAL)) # ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”
        return

    total_processed_urls = 0 # ì‹¤ì œë¡œ ì²˜ë¦¬ ì‹œë„í•œ URL ìˆ˜
    successful_requests_map = {"Google": 0, "Bing": 0, "Naver": 0, "Total":0}
    
    platforms_to_index = []
    if google_enabled: platforms_to_index.append("Google")
    if bing_enabled: platforms_to_index.append("Bing")
    if naver_enabled: platforms_to_index.append("Naver")

    # URL ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
    status_data = load_url_status()
    current_time = int(time.time())
    
    # ì‹œê°„ëŒ€ì— ë”°ë¥¸ ì²˜ë¦¬ ì „ëµ ê²°ì •
    current_hour = datetime.datetime.now().hour
    prioritize_recent = True  # ê¸°ë³¸ì ìœ¼ë¡œ ìµœì‹  URL ìš°ì„ 
    prioritize_failed = False  # ê¸°ë³¸ì ìœ¼ë¡œ ì‹¤íŒ¨í•œ URLì€ ë‚˜ì¤‘ì— ì²˜ë¦¬
    
    # ì‹œê°„ëŒ€ì— ë”°ë¼ ì „ëµ ë³€ê²½
    if current_hour >= 16:  # ì˜¤í›„ 4ì‹œ ì´í›„
        add_log("ğŸ•™ ì˜¤í›„ ì‹œê°„ëŒ€ì…ë‹ˆë‹¤. ëˆ„ë½/ì‹¤íŒ¨í•œ URLì„ ìš°ì„  ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        prioritize_failed = True  # ì‹¤íŒ¨í•œ URL ìš°ì„ 
    else:
        add_log("ğŸ•™ ì˜¤ì „/ì˜¤í›„ ì‹œê°„ëŒ€ì…ë‹ˆë‹¤. ìµœì‹  URLì„ ìš°ì„  ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ê° í”Œë«í¼ë³„ ì²˜ë¦¬í•  URL ê°œìˆ˜ ê³„ì‚°
    platform_pending_urls = {}
    for platform in platforms_to_index:
        platform_pending_urls[platform] = get_pending_urls(
            urls, platform, current_time, 
            prioritize_recent=prioritize_recent, 
            prioritize_failed=prioritize_failed
        )
    
    total_api_calls = sum(len(platform_pending_urls[platform]) for platform in platforms_to_index)
    
    root.after(0, add_log, f"ğŸ“ ì´ {len(urls)}ê°œ URL ì¤‘ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ URL ìˆ˜:")
    for platform in platforms_to_index:
        pending_count = len(platform_pending_urls[platform])
        remaining_quota = get_remaining_quota(platform)
        root.after(0, add_log, f"- {platform}: {pending_count}ê°œ (ë‚¨ì€ í• ë‹¹ëŸ‰: {remaining_quota}ê°œ)")
    root.after(0, add_log, f"ğŸ”„ ì´ ì˜ˆìƒ API í˜¸ì¶œ ìˆ˜: {total_api_calls}")
    
    processed_api_calls = 0
    
    google_indexing_service = None
    if google_enabled:
        google_indexing_service = get_indexing_service()
        if not google_indexing_service:
            root.after(0, add_log, "âŒ Google API ì„œë¹„ìŠ¤ ê°ì²´ ìƒì„± ì‹¤íŒ¨. Google ìš”ì²­ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            if "Google" in platforms_to_index:
                 total_api_calls -= len(platform_pending_urls["Google"])
                 platforms_to_index.remove("Google") # êµ¬ê¸€ í”Œë«í¼ ì œì™¸
            google_enabled = False 

    # ê° í”Œë«í¼ë³„ ìƒ‰ì¸ ì²˜ë¦¬
    exit_processing = False  # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ í”Œë˜ê·¸
    
    for platform in platforms_to_index:
        if exit_processing:
            break
        
        pending_urls = platform_pending_urls[platform]
        batch_size = GOOGLE_BATCH_SIZE if platform == "Google" else BING_BATCH_SIZE if platform == "Bing" else NAVER_BATCH_SIZE
        
        if not pending_urls:
            root.after(0, add_log, f"â„¹ï¸ {platform}: ì²˜ë¦¬í•  URLì´ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # í• ë‹¹ëŸ‰ í™•ì¸
        remaining_quota = get_remaining_quota(platform)
        if remaining_quota <= 0:
            root.after(0, add_log, f"âš ï¸ {platform}: ì¼ì¼ í• ë‹¹ëŸ‰({DAILY_QUOTA[platform]}ê°œ)ì„ ëª¨ë‘ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í”Œë«í¼ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            continue
        
        # ì²˜ë¦¬í•  URL ê°œìˆ˜ë¥¼ í• ë‹¹ëŸ‰ì— ë§ê²Œ ì¡°ì •
        if len(pending_urls) > remaining_quota:
            root.after(0, add_log, f"â„¹ï¸ {platform}: í• ë‹¹ëŸ‰ì´ ì¶©ë¶„í•˜ì§€ ì•Šì•„ {len(pending_urls)}ê°œ ì¤‘ {remaining_quota}ê°œë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            pending_urls = pending_urls[:remaining_quota]
        
        # í•œ ë²ˆì— ìµœëŒ€ 10ê°œì”© ì²˜ë¦¬ (ìµœì‹  URL ìš°ì„ )
        max_per_run = min(10, len(pending_urls))
        if max_per_run < len(pending_urls):
            root.after(0, add_log, f"â„¹ï¸ {platform}: íš¨ìœ¨ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ í•œ ë²ˆì— 10ê°œì”© ì²˜ë¦¬í•©ë‹ˆë‹¤ (ìµœì‹  ìˆœ). ë‚˜ë¨¸ì§€ëŠ” ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
            pending_urls = pending_urls[:max_per_run]
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
        batch_count = (len(pending_urls) + batch_size - 1) // batch_size
        root.after(0, add_log, f"ğŸ“¦ {platform}: {batch_count}ê°œ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        for batch_idx in range(batch_count):
            if exit_processing:
                break
                
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(pending_urls))
            batch_urls = pending_urls[start_idx:end_idx]
            
            root.after(0, add_log, f"ğŸ”„ {platform}: ë°°ì¹˜ {batch_idx + 1}/{batch_count} ì²˜ë¦¬ ì¤‘... ({len(batch_urls)}ê°œ URL)")
            
            for url in batch_urls:
                result = STATUS_PENDING
                
                if platform == "Google" and google_enabled:
                    if google_indexing_service:
                        result = call_google_indexing_api(google_indexing_service, url)
                    else:
                        result = STATUS_ERROR
                elif platform == "Bing" and bing_enabled:
                    result = call_bing_indexing_api(url, BING_API_KEY)
                elif platform == "Naver" and naver_enabled:
                    result = call_naver_indexing_api(url, NAVER_CLIENT_ID, NAVER_CLIENT_SECRET)
                
                processed_api_calls += 1
                if result == STATUS_SUCCESS:
                    successful_requests_map[platform] = successful_requests_map.get(platform, 0) + 1
                    successful_requests_map["Total"] = successful_requests_map.get("Total", 0) + 1
                
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€ ì‹œ í”Œë«í¼ ì²˜ë¦¬ ì¤‘ë‹¨
                if result == STATUS_QUOTA_EXCEEDED:
                    if platform == "Google":  # êµ¬ê¸€ í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
                        exit_processing = True
                        root.after(0, add_log, f"âš ï¸ {platform} í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ì „ì²´ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        break
                    else:  # ë‹¤ë¥¸ í”Œë«í¼ì€ í•´ë‹¹ í”Œë«í¼ë§Œ ì¤‘ë‹¨
                        root.after(0, add_log, f"âš ï¸ {platform} í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ í•´ë‹¹ í”Œë«í¼ ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        break
                
                root.after(0, update_progress_bar, processed_api_calls, total_api_calls)
                
                # ë°°ì¹˜ ë‚´ ê° ìš”ì²­ ì‚¬ì´ì— ì•½ê°„ì˜ ì§€ì—°
                if processed_api_calls < total_api_calls and not exit_processing:
                    time.sleep(0.5)
            
            # ë°°ì¹˜ ê°„ ì§€ì—° (í• ë‹¹ëŸ‰ ì œí•œ ë°©ì§€)
            if batch_idx < batch_count - 1 and not exit_processing:
                delay_message = f"â±ï¸ {platform}: ë‹¤ìŒ ë°°ì¹˜ ì²˜ë¦¬ ì „ 10ì´ˆ ëŒ€ê¸° ì¤‘..."
                root.after(0, add_log, delay_message)
                time.sleep(10)  # ë°°ì¹˜ ê°„ 10ì´ˆ ëŒ€ê¸°
        
        # í”Œë«í¼ ê°„ ì§€ì—°
        if platform != platforms_to_index[-1] and not exit_processing:
            platform_delay_message = f"â±ï¸ ë‹¤ìŒ í”Œë«í¼ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „ 5ì´ˆ ëŒ€ê¸° ì¤‘..."
            root.after(0, add_log, platform_delay_message)
            time.sleep(5)  # í”Œë«í¼ ê°„ 5ì´ˆ ëŒ€ê¸°

    # ì‘ì—… ì™„ë£Œ í›„ ìš”ì•½ ì •ë³´ ì¶œë ¥
    if exit_processing:
        summary_message = "âš ï¸ í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ìƒ‰ì¸ ìš”ì²­ í”„ë¡œì„¸ìŠ¤ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
    else:
        summary_message = "ğŸ‰ ëª¨ë“  ìƒ‰ì¸ ìš”ì²­ í”„ë¡œì„¸ìŠ¤ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
        
    summary_message += f"ì²˜ë¦¬ ì™„ë£Œëœ URL ìˆ˜: {processed_api_calls}\n"
    
    # ìƒíƒœë³„ ê²°ê³¼ ì¹´ìš´íŠ¸
    status_counts = {
        STATUS_SUCCESS: 0,
        STATUS_ERROR: 0,
        STATUS_TIMEOUT: 0,
        STATUS_UNKNOWN: 0,
        STATUS_REQUESTED: 0,
        STATUS_QUOTA_EXCEEDED: 0
    }
    
    # ìƒíƒœ ë°ì´í„° ê°±ì‹  ë° ì¹´ìš´íŠ¸
    status_data = load_url_status()
    for url in urls:
        for platform in platforms_to_index:
            if url in status_data and platform in status_data[url]:
                status = status_data[url][platform]['status']
                if status in status_counts:
                    status_counts[status] += 1
    
    # ìƒíƒœë³„ ê²°ê³¼ ì¶œë ¥
    summary_message += f"\nìš”ì²­ ê²°ê³¼ ìƒì„¸:\n"
    summary_message += f"âœ… ì„±ê³µ: {status_counts[STATUS_SUCCESS]}ê°œ\n"
    summary_message += f"âŒ ì‹¤íŒ¨: {status_counts[STATUS_ERROR]}ê°œ\n"
    summary_message += f"â±ï¸ ì‹œê°„ ì´ˆê³¼: {status_counts[STATUS_TIMEOUT]}ê°œ\n"
    summary_message += f"â“ ì‘ë‹µ ë¶ˆë¶„ëª…: {status_counts[STATUS_UNKNOWN]}ê°œ\n"
    summary_message += f"ğŸ”„ ìš”ì²­ ì¤‘: {status_counts[STATUS_REQUESTED]}ê°œ\n"
    if status_counts[STATUS_QUOTA_EXCEEDED] > 0:
        summary_message += f"âš ï¸ í• ë‹¹ëŸ‰ ì´ˆê³¼: {status_counts[STATUS_QUOTA_EXCEEDED]}ê°œ\n"
    
    # í”Œë«í¼ë³„ ê²°ê³¼ ì¶œë ¥
    summary_message += f"\ní”Œë«í¼ë³„ ì„±ê³µ ê±´ìˆ˜:\n"
    summary_message += f"Google: {successful_requests_map['Google']}ê°œ\n"
    summary_message += f"Bing: {successful_requests_map['Bing']}ê°œ\n"
    summary_message += f"Naver: {successful_requests_map['Naver'] if naver_enabled else 0}ê°œ\n"
    
    # í• ë‹¹ëŸ‰ ì •ë³´ ì¶œë ¥
    quota_data = load_daily_quota()
    summary_message += f"\ní”Œë«í¼ë³„ í• ë‹¹ëŸ‰ ì‚¬ìš© í˜„í™©:\n"
    for platform in platforms_to_index:
        used = quota_data["usage"].get(platform, 0)
        total = DAILY_QUOTA.get(platform, 0)
        remaining = max(0, total - used)
        summary_message += f"{platform}: {used}/{total}ê°œ ì‚¬ìš© (ë‚¨ì€ í• ë‹¹ëŸ‰: {remaining}ê°œ)\n"

    # ì‹¤íŒ¨í•œ URLì´ ìˆëŠ”ì§€ í™•ì¸
    failed_count = status_counts[STATUS_ERROR] + status_counts[STATUS_TIMEOUT]
    if failed_count > 0:
        summary_message += f"\nì‹¤íŒ¨í•œ URLì€ ë‹¤ìŒ ìƒ‰ì¸ ìš”ì²­ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œë„ë©ë‹ˆë‹¤.\n"
        summary_message += "ì¬ì‹œë„ëŠ” ë§ˆì§€ë§‰ ì‹œë„ í›„ ì•½ 2ì‹œê°„ ë’¤ì— ê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    # ì²˜ë¦¬ ì „ëµ ì•ˆë‚´
    if prioritize_failed:
        summary_message += f"\nğŸ•™ í˜„ì¬ ì‹œê°„ëŒ€ëŠ” ì˜¤í›„ ì‹œê°„ìœ¼ë¡œ, ëˆ„ë½/ì‹¤íŒ¨í•œ URLì„ ìš°ì„  ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."
    else:
        summary_message += f"\nğŸ•™ í˜„ì¬ ì‹œê°„ëŒ€ëŠ” ì˜¤ì „/ì˜¤í›„ ì‹œê°„ìœ¼ë¡œ, ìµœì‹  URLì„ ìš°ì„  ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."

    root.after(0, add_log, summary_message)
    root.after(0, lambda: progress_fill.config(width=0)) # ì§„í–‰ë¥  ë°” ì´ˆê¸°í™”
    root.after(0, lambda: request_button.config(state=tk.NORMAL)) # ë²„íŠ¼ ë‹¤ì‹œ í™œì„±í™”

    # ê²°ê³¼ ë©”ì‹œì§€ í‘œì‹œ
    result_message = (
        f"ìƒ‰ì¸ ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ\n\n"
        f"ì´ ì²˜ë¦¬: {processed_api_calls}ê°œ URL\n"
        f"âœ… ì„±ê³µ: {status_counts[STATUS_SUCCESS]}ê°œ\n"
        f"âŒ ì‹¤íŒ¨: {status_counts[STATUS_ERROR]}ê°œ\n"
        f"â±ï¸ ì‹œê°„ ì´ˆê³¼: {status_counts[STATUS_TIMEOUT]}ê°œ\n"
        f"â“ ì‘ë‹µ ë¶ˆë¶„ëª…: {status_counts[STATUS_UNKNOWN]}ê°œ\n"
    )
    
    if exit_processing:
        result_message += f"\nâš ï¸ í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ ì²˜ë¦¬ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    result_message += f"\n\në‚¨ì€ í• ë‹¹ëŸ‰:"
    for platform in platforms_to_index:
        remaining = get_remaining_quota(platform)
        result_message += f"\n{platform}: {remaining}ê°œ"
    
    if prioritize_failed:
        result_message += f"\n\nğŸ•™ ì˜¤í›„ ì‹œê°„ëŒ€: ëˆ„ë½/ì‹¤íŒ¨í•œ URL ìš°ì„  ì²˜ë¦¬ë¨"
    else:
        result_message += f"\n\nğŸ•™ ì˜¤ì „/ì˜¤í›„ ì‹œê°„ëŒ€: ìµœì‹  URL ìš°ì„  ì²˜ë¦¬ë¨"
    
    result_message += f"\n\nURL ìƒíƒœëŠ” 'ğŸ“Š URL ìƒíƒœ' ë²„íŠ¼ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    
    root.after(0, lambda: messagebox.showinfo("ìƒ‰ì¸ ìš”ì²­ ì™„ë£Œ", result_message))
    
    # êµ¬ê¸€ í• ë‹¹ëŸ‰ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìœ¼ë©´ í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì—¬ë¶€ í™•ì¸
    if exit_processing:
        def confirm_exit():
            if messagebox.askyesno(
                "í”„ë¡œê·¸ë¨ ì¢…ë£Œ", 
                "Google í• ë‹¹ëŸ‰ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                "2ì‹œê°„ í›„ì— ë‹¤ì‹œ ì‹œë„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
                "í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
            ):
                root.destroy()
        
        root.after(1000, confirm_exit)

def update_progress_bar(completed, total):
    if total > 0:
        percentage = (completed / total) * 100
        # ì§„í–‰ë¥  ë°” ìµœëŒ€ ë„ˆë¹„ëŠ” 760ìœ¼ë¡œ ê³ ì •ë˜ì–´ ìˆìŒ
        bar_width = int(percentage / 100 * (progress_frame.winfo_width() or 760)) # ì´ˆê¸°ì—ëŠ” ë„ˆë¹„ê°€ 0ì¼ ìˆ˜ ìˆìŒ
        progress_fill.config(width=bar_width)
    else: # totalì´ 0ì´ë©´ ì§„í–‰ë¥  ë°”ë„ 0
        progress_fill.config(width=0)

# --- ë²„íŠ¼ë“¤ ---
button_frame = tk.Frame(root, bg="#2C3E50")
button_frame.pack(pady=10)

request_button = tk.Button(button_frame, text="ğŸš€ ìƒ‰ì¸ ìš”ì²­ ì‹œì‘", command=start_indexing_process,
                           bg="#667eea", fg="white", font=("Segoe UI", 10, "bold"), relief="raised", bd=2)
request_button.pack(side=tk.LEFT, padx=10, pady=5)

settings_main_button = tk.Button(button_frame, text="âš™ï¸ API ì„¤ì •", command=open_settings_window,
                            bg="#455A64", fg="white", font=("Segoe UI", 10), relief="raised", bd=2)
settings_main_button.pack(side=tk.LEFT, padx=5, pady=5)

status_button = tk.Button(button_frame, text="ğŸ“Š URL ìƒíƒœ", command=open_url_status_window,
                       bg="#3498db", fg="white", font=("Segoe UI", 10), relief="raised", bd=2)
status_button.pack(side=tk.LEFT, padx=5, pady=5)

quota_button = tk.Button(button_frame, text="ğŸ“ˆ í• ë‹¹ëŸ‰ ê´€ë¦¬", command=open_quota_manager,
                      bg="#f39c12", fg="white", font=("Segoe UI", 10), relief="raised", bd=2)
quota_button.pack(side=tk.LEFT, padx=5, pady=5)

# --- ì§„í–‰ë¥  ë°” ---
progress_container = tk.Frame(root, bg="#2C3E50") # ë°°ê²½ìƒ‰ ì¼ì¹˜
progress_container.pack(pady=10, padx=20, fill=tk.X)

progress_frame = tk.Frame(progress_container, bg="#E0E0E0", height=10, relief="flat", bd=0)
progress_frame.pack(fill=tk.X) # ë„ˆë¹„ë¥¼ ì±„ìš°ë„ë¡ í•¨

progress_fill = tk.Frame(progress_frame, bg="#667eea", width=0, height=10)
progress_fill.pack(side=tk.LEFT) # fill=tk.Y ë¶ˆí•„ìš”, ì–´ì°¨í”¼ height ê³ ì •

# --- ë¡œê·¸ ì˜ì—­ ---
log_label = tk.Label(root, text="ë¡œê·¸", font=("Segoe UI", 10, "bold"), fg="white", bg="#2C3E50")
log_label.pack(anchor=tk.W, padx=20, pady=(10,0)) # pady ìƒë‹¨ì—ë§Œ ì ìš©

log_area = scrolledtext.ScrolledText(root, width=90, height=15,
                                     font=("Courier New", 9), bg="#2D3748", fg="#E2E8F0",
                                     bd=2, relief="groove", wrap=tk.WORD) # wrap=tk.WORD ì¶”ê°€ (ê°€ë¡œ ìŠ¤í¬ë¡¤ ë°©ì§€)
log_area.pack(pady=(0,10), padx=20, fill=tk.BOTH, expand=True) # pady í•˜ë‹¨ì—ë§Œ ì ìš©

# ì´ˆê¸° ë¡œê·¸ ë©”ì‹œì§€
add_log("SEO ìƒ‰ì¸ ë„êµ¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
add_log("ì‚¬ì´íŠ¸ë§µ URLì„ ì…ë ¥í•˜ê³  'ìƒ‰ì¸ ìš”ì²­ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
add_log("ì£¼ì˜: API í‚¤, ì‚¬ì´íŠ¸ URL ë“±ì€ ì½”ë“œ ìƒë‹¨ì—ì„œ ì‹¤ì œ ê°’ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")

# Tkinter ì´ë²¤íŠ¸ ë£¨í”„ ì‹œì‘
root.mainloop()